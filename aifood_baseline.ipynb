{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aifood baseline -在此基础上略微修改-95.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本baseline采用pytorch框架，应用ModelArts的Notebook进行开发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集获取\n",
    "将您OBS桶中的数据文件加载到此notebook中，将如下代码中\"obs-aifood-baseline\"修改成您OBS桶名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing as mox\n",
    "# path 最好换成自己的\n",
    "mox.file.copy_parallel('s3://obs-aifood-buptlin/obs-aifood-buptlin','./aifood/')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('aifood')\n",
    "# 这里我直接把预训练模型加载到了obs\n",
    "model_names = os.listdir('aifood/pretrained_models')\n",
    "print(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集，并将其分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 手动写一个类来读取数据\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "size = 224\n",
    "# 使用image net的mean std 简单的数据增强\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "train_transformer_ImageNet = transforms.Compose([\n",
    "    transforms.Resize((size,size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    " \n",
    "val_transformer_ImageNet = transforms.Compose([\n",
    "    transforms.Resize((size,size)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "# 目录文件\n",
    "data_dir = 'aifood/data/images'\n",
    "# 为了划分数据集，和自定义transform 所以参考如下链接写了一个这个\n",
    "# refer https://blog.csdn.net/ncc1995/article/details/91125964\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, filenames, labels, transform):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.filenames[idx]).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    "    \n",
    "def split_Train_Val_Data(data_dir, ratio, bs=64):\n",
    "    global train_len\n",
    "    global val_len\n",
    "    \"\"\" the sum of ratio must equal to 1\"\"\"\n",
    "    dataset = ImageFolder(data_dir)     # data_dir精确到分类目录的上一级\n",
    "    character = [[] for i in range(len(dataset.classes))]\n",
    "    print(dataset.class_to_idx)\n",
    "    for x, y in dataset.samples:  # 将数据按类标存放\n",
    "        character[y].append(x)\n",
    "#     print(dataset.samples)\n",
    "    train_inputs, val_inputs, test_inputs = [], [], []\n",
    "    train_labels, val_labels, test_labels = [], [], []\n",
    "    for i, data in enumerate(character):   # data为一类图片\n",
    "        num_sample_train = int(len(data) * ratio[0])\n",
    "        #print(num_sample_train)\n",
    "        num_sample_val = int(len(data) * ratio[1])\n",
    "        num_val_index = num_sample_train + num_sample_val\n",
    "        # 这里打乱一下数据，实验表明，不打乱也没事\n",
    "        random.seed(7)\n",
    "        random.shuffle(data)\n",
    "        \n",
    "        for x in data[:num_sample_train]:\n",
    "            train_inputs.append(str(x))\n",
    "            train_labels.append(i)\n",
    "        for x in data[num_sample_train:num_val_index]:\n",
    "            val_inputs.append(str(x))\n",
    "            val_labels.append(i)\n",
    "    \n",
    "    train_len = len(train_inputs)\n",
    "    val_len = len(val_inputs)\n",
    "    print(\"train_length:%d,val length:%d\" %(train_len,val_len))\n",
    "    \n",
    "    train_dst = MyDataset(train_inputs, train_labels, train_transformer_ImageNet)\n",
    "    valid_dst = MyDataset(val_inputs, val_labels, val_transformer_ImageNet)\n",
    "    train_dataloader = DataLoader(train_dst,\n",
    "                                  batch_size=bs, shuffle=True)\n",
    "    val_dataloader = DataLoader(valid_dst,\n",
    "                                  batch_size=bs, shuffle=False)\n",
    " \n",
    "    return train_dataloader, val_dataloader\n",
    "# 定义pytorch的dataloader，数据划分0.9 可以提升一个点左右\n",
    "data_loader = split_Train_Val_Data(data_dir,(0.9,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了保证后面和官方的baseline一致，所以可以这么写\n",
    "dataloders = {x:  data_loader[i] for i,x in enumerate(['train', 'val']) }\n",
    "dataset_sizes = {'train':train_len, 'val':val_len}\n",
    "print(dataset_sizes)\n",
    "# use gpu or not\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里计算了一下所有照片的均值，方差，可以酌情替换imageNet 的\n",
    "# mean std = [0.6736, 0.5654, 0.4031],[0.1994, 0.2248, 0.2528]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lossfunc, optimizer, scheduler, num_epochs=10):\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    train_acc = []\n",
    "    valid_acc = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "#                 \n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                \n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                \n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = lossfunc(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data).to(torch.float32)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'val':\n",
    "                valid_acc.append(epoch_acc)\n",
    "            else:\n",
    "                train_acc.append(epoch_acc)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        # 这里使用了学习率调整策略\n",
    "        scheduler.step(valid_acc[-1])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        elapsed_time // 60, elapsed_time % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "  \n",
    "    return model,train_acc,valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 之前手写的标签平滑可以直接用，也可以不用。\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# export label smoothing\n",
    "from torch.autograd import Variable\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction == 'mean' else loss.sum() if reduction == 'sum' else loss\n",
    "def lin_comb(a, b, epsilon):\n",
    "    return epsilon * a + b * (1 - epsilon)\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, epsilon: float = 0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.epsilon, self.reduction = epsilon, reduction\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss / c, nll, self.epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "采用resnet50神经网络结构训练模型,模型训练需要一定时间，等待该段代码运行完成后再往下执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 这里模型选择比较短的resnet34 跑起来比较快\n",
    "model_ft = models.resnet34(pretrained=False)\n",
    "# 训练权重我自己下载的，然后拷贝到了notebook目录下面\n",
    "model_ft.load_state_dict(torch.load('aifood/pretrained_models/resnet34-333f7ec4.pth'))\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# 可以如下在全连接层前面加入dropout来防止过拟合\n",
    "# model_ft.fc = nn.Sequential(\n",
    "#     nn.Dropout(0.2),\n",
    "#     nn.Linear(2048, 10)\n",
    "# )\n",
    "model_ft.fc=nn.Linear(num_ftrs, 10)\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "# define loss function\n",
    "lossfunc = nn.CrossEntropyLoss()\n",
    "# lossfunc = LabelSmoothingCrossEntropy()\n",
    "\n",
    "# 这里直接训练整个网络，也可以像原来baseline先fc后解冻整个网络\n",
    "parameters = list(model_ft.parameters())\n",
    "optimizer_ft = optim.SGD(parameters, lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# 使用ReduceLROnPlateau学习调度器，如果三个epoch准确率没有提升，则减少学习率\n",
    "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft,mode='max',patience=3,verbose=True)\n",
    "model_ft,train_acc,valid_acc = train_model(model=model_ft,\n",
    "                           lossfunc=lossfunc,\n",
    "                           optimizer=optimizer_ft,\n",
    "                           scheduler=exp_lr_scheduler,\n",
    "                           num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc 曲线\n",
    "# best = 9540\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "plt.plot(train_acc,label=\"train\")\n",
    "plt.plot(valid_acc,label='valid')\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练好的模型保存下来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将训练好的模型保存至OBS\n",
    "将模型保存到OBS桶中model文件夹下，为后续推理测试、模型提交做准备。将如下代码中\"obs-aifood-baseline\"修改成您OBS桶的名称。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing as mox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意拷贝到自己的目录环境下面即可\n",
    "mox.file.copy('./model.pth','s3://obs-aifood-buptlin/obs-aifood-buptlin/outputs/model/resnet-50.pth')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最重要的就是别忘记修改customize_service.py，一定部署后再去发布再有分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改里面的网络定义函数resnet50即可,接口通常修改为和val的tansform一致\n",
    "mean,std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "infer_transformation = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std)\n",
    "])\n",
    "\n",
    "def resnet50(model_path, **kwargs):\n",
    "\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = models.resnet34(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 10)\n",
    "    model.load_state_dict(torch.load(model_path,map_location ='cpu'))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
